{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80196f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_json(r\"D:\\gigaword\\train.jsonl\",lines=True)\n",
    "\n",
    "# Sample 25% of the data\n",
    "df = data.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b8f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987231</th>\n",
       "      <td>gigaword-train-987231</td>\n",
       "      <td>generally speaking , a fashion show and a runw...</td>\n",
       "      <td>bravo replacing runway with the fashion show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>gigaword-train-79954</td>\n",
       "      <td>british detectives tuesday arrested ## people ...</td>\n",
       "      <td>british police arrest ## over airport robbery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567130</th>\n",
       "      <td>gigaword-train-567130</td>\n",
       "      <td>former us president bill clinton launched an a...</td>\n",
       "      <td>clinton calls for haiti aid as girl 's recover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500891</th>\n",
       "      <td>gigaword-train-500891</td>\n",
       "      <td>pakistan 's economy is expected to emerge from...</td>\n",
       "      <td>pakistan economy expected to emerge from doldrums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>gigaword-train-55399</td>\n",
       "      <td>a car bomb exploded near an australian militar...</td>\n",
       "      <td>car bomb targets australian convoy as iraq pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686403</th>\n",
       "      <td>gigaword-train-686403</td>\n",
       "      <td>a palestinian human rights group protested thu...</td>\n",
       "      <td>rights group protests israeli clampdown on wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100678</th>\n",
       "      <td>gigaword-train-100678</td>\n",
       "      <td>urgent new talks to end a week-old strike by f...</td>\n",
       "      <td>french truckers strike snowballs talks blocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488468</th>\n",
       "      <td>gigaword-train-488468</td>\n",
       "      <td>a us federal on wednesday ordered sudan to pay...</td>\n",
       "      <td>us judge orders sudan to pay #.# million for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583782</th>\n",
       "      <td>gigaword-train-583782</td>\n",
       "      <td>world leaders have stiffened their opposition ...</td>\n",
       "      <td>world stiffens opposition to us strike on iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551383</th>\n",
       "      <td>gigaword-train-551383</td>\n",
       "      <td>european farmers protesting the fall of milk p...</td>\n",
       "      <td>eu farmers protest turns violent in luxembourg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "987231  gigaword-train-987231   \n",
       "79954    gigaword-train-79954   \n",
       "567130  gigaword-train-567130   \n",
       "500891  gigaword-train-500891   \n",
       "55399    gigaword-train-55399   \n",
       "...                       ...   \n",
       "686403  gigaword-train-686403   \n",
       "100678  gigaword-train-100678   \n",
       "488468  gigaword-train-488468   \n",
       "583782  gigaword-train-583782   \n",
       "551383  gigaword-train-551383   \n",
       "\n",
       "                                                     text  \\\n",
       "987231  generally speaking , a fashion show and a runw...   \n",
       "79954   british detectives tuesday arrested ## people ...   \n",
       "567130  former us president bill clinton launched an a...   \n",
       "500891  pakistan 's economy is expected to emerge from...   \n",
       "55399   a car bomb exploded near an australian militar...   \n",
       "...                                                   ...   \n",
       "686403  a palestinian human rights group protested thu...   \n",
       "100678  urgent new talks to end a week-old strike by f...   \n",
       "488468  a us federal on wednesday ordered sudan to pay...   \n",
       "583782  world leaders have stiffened their opposition ...   \n",
       "551383  european farmers protesting the fall of milk p...   \n",
       "\n",
       "                                                  summary  \n",
       "987231       bravo replacing runway with the fashion show  \n",
       "79954       british police arrest ## over airport robbery  \n",
       "567130  clinton calls for haiti aid as girl 's recover...  \n",
       "500891  pakistan economy expected to emerge from doldrums  \n",
       "55399   car bomb targets australian convoy as iraq pro...  \n",
       "...                                                   ...  \n",
       "686403  rights group protests israeli clampdown on wes...  \n",
       "100678     french truckers strike snowballs talks blocked  \n",
       "488468  us judge orders sudan to pay #.# million for a...  \n",
       "583782     world stiffens opposition to us strike on iraq  \n",
       "551383     eu farmers protest turns violent in luxembourg  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec16c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b2b52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text'] + ' ' + df['summary']\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the combined corpus\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# Convert text and summary columns into sequences\n",
    "X = tokenizer.texts_to_sequences(df['text'])\n",
    "Y = tokenizer.texts_to_sequences(df['summary'])\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_len = 100  # You can adjust this value based on your dataset\n",
    "\n",
    "# Pad sequences\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "Y = pad_sequences(Y, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31e6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100  # Adjust this value based on your requirements\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "# Define maximum sequence length\n",
    "max_len = 100  # Adjust this value based on your dataset and requirements\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeacf9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New jobless numbers are a bit of a mixed bag f...</td>\n",
       "      <td>New jobless numbers a mixed bag for Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A car filled with Christmas presents was stole...</td>\n",
       "      <td>Car filled with Christmas presents stolen in M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A mariachi band has serenaded Donald Trump on ...</td>\n",
       "      <td>Mariachi band serenaded Donald Trump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lena Dunham was taken to the hospital Saturday...</td>\n",
       "      <td>Lena Dunham Will Undergo Surgery For Ruptured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>At least 13 people are reportedly dead and man...</td>\n",
       "      <td>At least 13 dead after tour bus collided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A Chicago cop is being praised for his good de...</td>\n",
       "      <td>Chicago cop praised for buying homeless man Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Coffee could be extinct by 2080 because of the...</td>\n",
       "      <td>Coffee could be extinct by 2080 because of cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>An American student and part-time model was fo...</td>\n",
       "      <td>American Student and Part-Time Model Found Dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The Apple Watch will be available in retail st...</td>\n",
       "      <td>Apple Watch Will Be Available In Stores In Two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The death of a teenager found in a North Austi...</td>\n",
       "      <td>Death of teenager found with cobra bites ruled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>A man has been charged with murder after a bod...</td>\n",
       "      <td>Man charged with murder after body found in ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Glen Campbell is suffering from Alzheimerâ€™s di...</td>\n",
       "      <td>Glen Campbell is suffering from Alzheimerâ€™s di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Asbestos has been found in the charred remains...</td>\n",
       "      <td>Asbestos found in charred remains of beach hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Paris Hilton Arrested for Cocaine in Las Vegas...</td>\n",
       "      <td>Paris Hilton Arrested for Cocaine in Las Vegas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A body pulled from Lake Michigan has been iden...</td>\n",
       "      <td>Body pulled from Lake Michigan identified as m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  \\\n",
       "0    1  New jobless numbers are a bit of a mixed bag f...   \n",
       "1    2  A car filled with Christmas presents was stole...   \n",
       "2    3  A mariachi band has serenaded Donald Trump on ...   \n",
       "3    4  Lena Dunham was taken to the hospital Saturday...   \n",
       "4    5  At least 13 people are reportedly dead and man...   \n",
       "5    6  A Chicago cop is being praised for his good de...   \n",
       "6    7  Coffee could be extinct by 2080 because of the...   \n",
       "7    8  An American student and part-time model was fo...   \n",
       "8    9  The Apple Watch will be available in retail st...   \n",
       "9   10  The death of a teenager found in a North Austi...   \n",
       "10  11  A man has been charged with murder after a bod...   \n",
       "11  12  Glen Campbell is suffering from Alzheimerâ€™s di...   \n",
       "12  13  Asbestos has been found in the charred remains...   \n",
       "13  14  Paris Hilton Arrested for Cocaine in Las Vegas...   \n",
       "14  15  A body pulled from Lake Michigan has been iden...   \n",
       "\n",
       "                                              summary  \n",
       "0           New jobless numbers a mixed bag for Obama  \n",
       "1   Car filled with Christmas presents stolen in M...  \n",
       "2               Mariachi band serenaded Donald Trump.  \n",
       "3   Lena Dunham Will Undergo Surgery For Ruptured ...  \n",
       "4   At least 13 dead after tour bus collided with ...  \n",
       "5   Chicago cop praised for buying homeless man Ch...  \n",
       "6   Coffee could be extinct by 2080 because of cli...  \n",
       "7   American Student and Part-Time Model Found Dea...  \n",
       "8   Apple Watch Will Be Available In Stores In Two...  \n",
       "9   Death of teenager found with cobra bites ruled...  \n",
       "10  Man charged with murder after body found in ho...  \n",
       "11  Glen Campbell is suffering from Alzheimerâ€™s di...  \n",
       "12  Asbestos found in charred remains of beach hou...  \n",
       "13    Paris Hilton Arrested for Cocaine in Las Vegas.  \n",
       "14  Body pulled from Lake Michigan identified as m...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define your data\n",
    "test_df = {\n",
    "    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    'text': [\n",
    "        \"New jobless numbers are a bit of a mixed bag for President Obama and his re-election bid.\",\n",
    "        \"A car filled with Christmas presents was stolen from a home in Melbourneâ€™s north-east on Christmas Day.\",\n",
    "        \"A mariachi band has serenaded Donald Trump on the sidewalk outside Trump Tower in New York City.\",\n",
    "        \"Lena Dunham was taken to the hospital Saturday and will undergo surgery for a ruptured ovarian cyst, her spokeswoman said.\",\n",
    "        \"At least 13 people are reportedly dead and many more are seriously injured after a tour bus collided with a semi-trailer in California.\",\n",
    "        \"A Chicago cop is being praised for his good deed after an image of him buying a homeless man Chipotle went viral.\",\n",
    "        \"Coffee could be extinct by 2080 because of the effects of climate change on coffee growing regions.\",\n",
    "        \"An American student and part-time model was found dead in her room at an Australian university, a police spokesman said.\",\n",
    "        \"The Apple Watch will be available in retail stores in two weeks, Apple announced Thursday.\",\n",
    "        \"The death of a teenager found in a North Austin parking lot with multiple cobra bites has been ruled a suicide.\",\n",
    "        \"A man has been charged with murder after a body was found in a home in Sydney's south yesterday.\",\n",
    "        \"Glen Campbell is suffering from Alzheimerâ€™s disease, the singer revealed to People.\",\n",
    "        \"Asbestos has been found in the charred remains of a beach house, gutted by a ferocious fire overnight in Palm Beach on Sydney's Northern Beaches.\",\n",
    "        \"Paris Hilton Arrested for Cocaine in Las Vegas was arrested for possession of cocaine Friday night in Las Vegas.\",\n",
    "        \"A body pulled from Lake Michigan has been identified as missing medical student Ambrose Monye, who disappeared weeks before his graduation, Chicago police confirmed to FoxNews.com Thursday.\"\n",
    "    ],\n",
    "    'summary': [\n",
    "        \"New jobless numbers a mixed bag for Obama\",\n",
    "        \"Car filled with Christmas presents stolen in Melbourne.\",\n",
    "        \"Mariachi band serenaded Donald Trump.\",\n",
    "        \"Lena Dunham Will Undergo Surgery For Ruptured Ovarian Cyst.\",\n",
    "        \"At least 13 dead after tour bus collided with semi-trailer in California.\",\n",
    "        \"Chicago cop praised for buying homeless man Chipotle.\",\n",
    "        \"Coffee could be extinct by 2080 because of climate change.\",\n",
    "        \"American Student and Part-Time Model Found Dead at Australian University.\",\n",
    "        \"Apple Watch Will Be Available In Stores In Two Weeks.\",\n",
    "        \"Death of teenager found with cobra bites ruled suicide.\",\n",
    "        \"Man charged with murder after body found in home in Sydney's south.\",\n",
    "        \"Glen Campbell is suffering from Alzheimerâ€™s disease.\",\n",
    "        \"Asbestos found in charred remains of beach house gutted by fire in Sydney.\",\n",
    "        \"Paris Hilton Arrested for Cocaine in Las Vegas.\",\n",
    "        \"Body pulled from Lake Michigan identified as missing medical student Ambrose Monye.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48d6e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = test_df['text'] \n",
    "\n",
    "# Convert text into sequences using the tokenizer fitted on the training data\n",
    "X_test = tokenizer.texts_to_sequences(test_df['text'])\n",
    "Y_test= tokenizer.texts_to_sequences(test_df['summary'])\n",
    "# Pad sequences to ensure consistent length\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65eff2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "962c4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaaa49ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 257s 2s/step - loss: 2.8552 - accuracy: 0.8981 - val_loss: 1.9902 - val_accuracy: 0.8167\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 244s 2s/step - loss: 0.9330 - accuracy: 0.9163 - val_loss: 1.9765 - val_accuracy: 0.8167\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 241s 2s/step - loss: 0.8421 - accuracy: 0.9193 - val_loss: 1.9865 - val_accuracy: 0.8167\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.7882 - accuracy: 0.9205 - val_loss: 1.8688 - val_accuracy: 0.8167\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 248s 2s/step - loss: 0.6874 - accuracy: 0.9211 - val_loss: 1.8788 - val_accuracy: 0.8173\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.6608 - accuracy: 0.9221 - val_loss: 1.9530 - val_accuracy: 0.8173\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 238s 2s/step - loss: 0.6463 - accuracy: 0.9225 - val_loss: 1.9968 - val_accuracy: 0.8173\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.6370 - accuracy: 0.9228 - val_loss: 2.0032 - val_accuracy: 0.8180\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 26876s 271s/step - loss: 0.6251 - accuracy: 0.9233 - val_loss: 2.0558 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 268s 3s/step - loss: 0.6167 - accuracy: 0.9237 - val_loss: 2.0968 - val_accuracy: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9169acf88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,validation_data=(X_test,Y_test),epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09441ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100  # Adjust this value based on your requirements\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "# Define maximum sequence length\n",
    "max_len = 100  # Adjust this value based on your dataset and requirements\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.SimpleRNN(units=128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05d0ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf04a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 245s 2s/step - loss: 0.6102 - accuracy: 0.9238 - val_loss: 2.0771 - val_accuracy: 0.8173\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6257s 63s/step - loss: 0.6064 - accuracy: 0.9238 - val_loss: 2.0224 - val_accuracy: 0.8187\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 248s 2s/step - loss: 0.5991 - accuracy: 0.9240 - val_loss: 2.1137 - val_accuracy: 0.8187\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 243s 2s/step - loss: 0.5932 - accuracy: 0.9242 - val_loss: 2.1114 - val_accuracy: 0.8187\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.5906 - accuracy: 0.9242 - val_loss: 2.1434 - val_accuracy: 0.8187\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 240s 2s/step - loss: 0.5825 - accuracy: 0.9244 - val_loss: 2.2082 - val_accuracy: 0.8187\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 245s 2s/step - loss: 0.5770 - accuracy: 0.9245 - val_loss: 2.2501 - val_accuracy: 0.8180\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1298s 13s/step - loss: 0.5718 - accuracy: 0.9248 - val_loss: 2.2405 - val_accuracy: 0.8180\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 317s 3s/step - loss: 0.5694 - accuracy: 0.9248 - val_loss: 2.2844 - val_accuracy: 0.8187\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 273s 3s/step - loss: 0.5614 - accuracy: 0.9252 - val_loss: 2.2752 - val_accuracy: 0.8180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8b56b35c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,validation_data=(X_test,Y_test),epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ef6c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.GRU(units=128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f36703d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64c760b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 307s 3s/step - loss: 3.0021 - accuracy: 0.9083 - val_loss: 1.8375 - val_accuracy: 0.8167\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 327s 3s/step - loss: 0.7484 - accuracy: 0.9201 - val_loss: 1.8133 - val_accuracy: 0.8167\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 261s 3s/step - loss: 0.7165 - accuracy: 0.9201 - val_loss: 1.7945 - val_accuracy: 0.8167\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 254s 3s/step - loss: 0.6826 - accuracy: 0.9202 - val_loss: 1.8941 - val_accuracy: 0.8167\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 254s 3s/step - loss: 0.6569 - accuracy: 0.9209 - val_loss: 1.9172 - val_accuracy: 0.8167\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 254s 3s/step - loss: 0.6439 - accuracy: 0.9212 - val_loss: 1.9633 - val_accuracy: 0.8167\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1641s 17s/step - loss: 0.6355 - accuracy: 0.9215 - val_loss: 1.9935 - val_accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 270s 3s/step - loss: 0.6288 - accuracy: 0.9218 - val_loss: 2.0325 - val_accuracy: 0.8173\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.6232 - accuracy: 0.9223 - val_loss: 2.0417 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 274s 3s/step - loss: 0.6179 - accuracy: 0.9227 - val_loss: 2.0653 - val_accuracy: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8c2b24948>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,validation_data=(X_test,Y_test),epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
